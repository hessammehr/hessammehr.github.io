<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title></title>
    <link
      rel="alternate"
      type="application/rss+xml"
      title="Hessam's blog RSS Feed"
      href="/feed.xml"
    />
    <link rel="stylesheet" href="/style.css" />
    <link rel="stylesheet" href="/primer.css" />
    <link
      rel="stylesheet"
      href="/light.css"
      media="(prefers-color-scheme: light)"
    />
    <link
      rel="stylesheet"
      href="/dark.css"
      media="(prefers-color-scheme: dark)"
    />
  </head>
  <body>
    <div class="container-lg px-3 my-5 markdown-body"><pre class="python"><code>import jax
import jax.numpy as jnp
import matplotlib.pyplot as plt
import numpy as np
import numpyro.distributions as dist
import seaborn as sns
from numpyro import deterministic, plate, sample
from numpyro.infer import MCMC, NUTS, SVI, Trace_ELBO
from numpyro.infer.autoguide import AutoNormal
from numpyro.optim import Adam
from PIL import Image

sns.set_theme(&#39;notebook&#39;, &#39;ticks&#39;, font=&#39;Arial&#39;)

plt.rcParams[&#39;figure.dpi&#39;] = 200</code></pre>
<h1 id="trialing-generative-processes-for-chemical-microscopy">Trialing generative processes for chemical microscopy</h1>
<p>Is it possible to use a generative process to model microscope images like this (and is it worth the effort?)</p>
<pre class="python"><code>img = Image.open(&#39;data/example.jpg&#39;)
img = img.resize((img.width // 2, img.height // 2))</code></pre>
<p>Try a couple of different colour spaces in case something interesting stands out.</p>
<pre class="python"><code>from skimage import color

img_array = np.array(img)
lab_img = color.rgb2lab(img_array)

fig, axes = plt.subplots(1, 3, figsize=(15, 5))

for i, (ax, title) in enumerate(zip(axes, [&#39;L channel&#39;, &#39;a channel&#39;, &#39;b channel&#39;])):
    im = ax.imshow(lab_img[:,:,i], cmap=&#39;gray&#39;)
    ax.set_title(title)
    fig.colorbar(im, ax=ax, fraction=0.03, pad=0.04)

plt.tight_layout()</code></pre>
<figure>
<img src="2024-12-28-droplet-generative-process_files/2024-12-28-droplet-generative-process_4_0.png" alt="" /><figcaption>png</figcaption>
</figure>
<pre class="python"><code>hsv_img = color.rgb2hsv(img_array)

fig, axes = plt.subplots(1, 3, figsize=(15, 5))

for i, (ax, title) in enumerate(zip(axes, [&#39;H channel&#39;, &#39;S channel&#39;, &#39;V channel&#39;])):
    im = ax.imshow(hsv_img[:,:,i], cmap=&#39;gray&#39;)
    ax.set_title(title)
    fig.colorbar(im, ax=ax, fraction=0.03, pad=0.04)

plt.tight_layout()</code></pre>
<figure>
<img src="2024-12-28-droplet-generative-process_files/2024-12-28-droplet-generative-process_5_0.png" alt="" /><figcaption>png</figcaption>
</figure>
<p>First approach, fixed number of droplets; model centres and radii</p>
<pre class="python"><code>def model1(w, h, n_droplets):
    with plate(&quot;droplets&quot;, n_droplets):
        x = sample(&quot;x&quot;, dist.Uniform(0, w))
        y = sample(&quot;y&quot;, dist.Uniform(0, h))
        r = sample(&quot;r&quot;, dist.LogNormal(1.5, 0.75))


mcmc = MCMC(NUTS(model1), num_warmup=1000, num_samples=100)
mcmc.run(jax.random.PRNGKey(0), w=img.width, h=img.height, n_droplets=100)
samples = mcmc.get_samples()

fig, ax = plt.subplots()
ax.imshow(np.ones_like(np.array(img)) * 255, cmap=&quot;gray&quot;)
for sample_no in range(5):
    for i in range(100):
        circle = plt.Circle(
            (samples[&quot;x&quot;][sample_no][i], samples[&quot;y&quot;][sample_no][i]),
            samples[&quot;r&quot;][sample_no][i],
            color=plt.cm.tab10(sample_no),
        )

        ax.add_artist(circle)</code></pre>
<pre><code>sample: 100%|██████████| 1100/1100 [00:09&lt;00:00, 111.22it/s, 15 steps of size 3.08e-01. acc. prob=0.84]</code></pre>
<figure>
<img src="2024-12-28-droplet-generative-process_files/2024-12-28-droplet-generative-process_7_1.png" alt="" /><figcaption>png</figcaption>
</figure>
<pre class="python"><code>def model2(w, h, n_droplets):
    # Sample droplet locations and sizes
    with plate(&quot;droplets&quot;, n_droplets):
        x = sample(&quot;x&quot;, dist.Uniform(0, w))
        y = sample(&quot;y&quot;, dist.Uniform(0, h))
        r = sample(&quot;r&quot;, dist.LogNormal(1.5, 0.75))
        
        # Sample HSV values for each droplet
        h_val = sample(&quot;h&quot;, dist.Uniform(0, 1))
        s_val = sample(&quot;s&quot;, dist.Beta(2, 2))
        v_val = sample(&quot;v&quot;, dist.Beta(5, 2))  # Biased towards brighter values

mcmc = MCMC(NUTS(model2), num_warmup=1000, num_samples=100)
mcmc.run(jax.random.PRNGKey(0), w=img.width, h=img.height, n_droplets=100)
samples = mcmc.get_samples()
samples = {k: np.array(v) for k, v in samples.items()}

# Visualize with HSV colors
fig, ax = plt.subplots()
ax.imshow(np.ones_like(np.array(img)) * 255, cmap=&quot;gray&quot;)
for i in range(100):
    circle = plt.Circle(
        (samples[&quot;x&quot;][0][i], samples[&quot;y&quot;][0][i]),
        samples[&quot;r&quot;][0][i],
        color=color.hsv2rgb(
            np.array(
                [
                    samples[&quot;h&quot;][0][i],
                    samples[&quot;s&quot;][0][i],
                    samples[&quot;v&quot;][0][i],
                ]
            )
        ),
    )
    ax.add_artist(circle)</code></pre>
<pre><code>sample: 100%|██████████| 1100/1100 [00:14&lt;00:00, 73.33it/s, 15 steps of size 2.52e-01. acc. prob=0.86] </code></pre>
<figure>
<img src="2024-12-28-droplet-generative-process_files/2024-12-28-droplet-generative-process_8_1.png" alt="" /><figcaption>png</figcaption>
</figure>
<pre class="python"><code>def model2(w, h, n_droplets):
    # Sample droplet locations and sizes
    with plate(&quot;droplets&quot;, n_droplets):
        x = sample(&quot;x&quot;, dist.Uniform(0, w))
        y = sample(&quot;y&quot;, dist.Uniform(0, h))
        r = sample(&quot;r&quot;, dist.LogNormal(1.5, 0.75))
        
        with plate(&quot;pixels&quot;, w * h):
            x_dist = jnp.abs(x - jnp.arange(w)[:, None])
            y_dist = jnp.abs(y - jnp.arange(h)[:, None])
            distance = jnp.sqrt(x_dist ** 2 + y_dist[:, None] ** 2)
            val = deterministic(&#39;val&#39;, jnp.sum(jnp.exp(-distance ** 2 / (2 * r ** 2)), axis=-1))


mcmc = MCMC(NUTS(model2), num_warmup=500, num_samples=10)
mcmc.run(jax.random.PRNGKey(0), w=img.width, h=img.height, n_droplets=100)
samples = mcmc.get_samples()
samples = {k: np.array(v) for k, v in samples.items()}

# show the first 3 samples
fig, axes = plt.subplots(1, 3, figsize=(15, 5))
for i, ax in enumerate(axes):
    ax.imshow(1 - samples[&#39;val&#39;][i], cmap=&#39;gray&#39;)</code></pre>
<pre><code>sample: 100%|██████████| 510/510 [00:06&lt;00:00, 78.05it/s, 15 steps of size 3.10e-01. acc. prob=0.85] </code></pre>
<figure>
<img src="2024-12-28-droplet-generative-process_files/2024-12-28-droplet-generative-process_9_1.png" alt="" /><figcaption>png</figcaption>
</figure>
<p>Not a bad generative process to start with. Now let’s just fit the hue channel …</p>
<pre class="python"><code>def model3(w, h, n_droplets, channel):
    # Sample droplet locations and sizes
    bg = sample(&quot;bg&quot;, dist.Uniform(0, 1))
    with plate(&quot;droplets&quot;, n_droplets):
        x = sample(&quot;x&quot;, dist.Uniform(0, 1))*w
        y = sample(&quot;y&quot;, dist.Uniform(0, 1))*h
        r = sample(&quot;r&quot;, dist.LogNormal(1.5, 0.75))
        amplitude = sample(&quot;amplitude&quot;, dist.HalfNormal())
        
        x_dist = jnp.abs(x - jnp.arange(w)[:, None])
        y_dist = jnp.abs(y - jnp.arange(h)[:, None])
        distance = jnp.sqrt(x_dist ** 2 + y_dist[:, None] ** 2)
        val = deterministic(&#39;val&#39;, bg + jnp.sum(amplitude[None, None, :] * jnp.exp(-distance ** 2 / (2 * r ** 2)), axis=-1))
        diff = deterministic(&#39;diff&#39;, val - channel)
    sample(&#39;obs&#39;, dist.Normal(0, 0.1), obs=val - channel)
</code></pre>
<p>Fitting, instead of sampling</p>
<pre class="python"><code>guide = AutoNormal(model3)
svi = SVI(model3, guide, Adam(0.02), Trace_ELBO())
svi_result = None
while True:
    svi_result = svi.run(jax.random.PRNGKey(0), 1000, img.width, img.height, 500, hsv_img[:,:,0], init_state=svi_result and svi_result.state)
    if svi_result.losses[0] - svi_result.losses[-1] &lt; 1000:
        break</code></pre>
<pre><code>100%|██████████| 1000/1000 [00:17&lt;00:00, 55.98it/s, init loss: 11135004.0000, avg. loss [951-1000]: 933170.7500]
100%|██████████| 1000/1000 [00:17&lt;00:00, 57.68it/s, init loss: 930588.8125, avg. loss [951-1000]: 877631.7500]
100%|██████████| 1000/1000 [00:17&lt;00:00, 57.46it/s, init loss: 878014.4375, avg. loss [951-1000]: 838963.0625]
100%|██████████| 1000/1000 [00:17&lt;00:00, 57.45it/s, init loss: 838473.2500, avg. loss [951-1000]: 813781.2500]
100%|██████████| 1000/1000 [00:17&lt;00:00, 55.65it/s, init loss: 813162.3750, avg. loss [951-1000]: 792063.2500]
100%|██████████| 1000/1000 [00:17&lt;00:00, 57.15it/s, init loss: 790267.4375, avg. loss [951-1000]: 775268.8125]
100%|██████████| 1000/1000 [00:17&lt;00:00, 56.96it/s, init loss: 774699.1875, avg. loss [951-1000]: 764176.7500]
100%|██████████| 1000/1000 [00:17&lt;00:00, 57.26it/s, init loss: 764443.5000, avg. loss [951-1000]: 754463.6250]
100%|██████████| 1000/1000 [00:17&lt;00:00, 56.95it/s, init loss: 754262.7500, avg. loss [951-1000]: 744407.1875]
100%|██████████| 1000/1000 [00:17&lt;00:00, 57.05it/s, init loss: 743674.8750, avg. loss [951-1000]: 739275.9375]
100%|██████████| 1000/1000 [00:17&lt;00:00, 57.13it/s, init loss: 739285.9375, avg. loss [951-1000]: 735915.7500]
100%|██████████| 1000/1000 [00:17&lt;00:00, 57.00it/s, init loss: 735452.8750, avg. loss [951-1000]: 731554.0000]
100%|██████████| 1000/1000 [00:17&lt;00:00, 57.09it/s, init loss: 730866.3750, avg. loss [951-1000]: 728556.8125]
100%|██████████| 1000/1000 [00:17&lt;00:00, 57.05it/s, init loss: 728374.0625, avg. loss [951-1000]: 722425.6250]
100%|██████████| 1000/1000 [00:17&lt;00:00, 57.14it/s, init loss: 721568.3750, avg. loss [951-1000]: 718221.0625]
100%|██████████| 1000/1000 [00:17&lt;00:00, 57.12it/s, init loss: 718202.4375, avg. loss [951-1000]: 713332.8125]
100%|██████████| 1000/1000 [00:17&lt;00:00, 57.09it/s, init loss: 713491.5625, avg. loss [951-1000]: 712046.0625]
100%|██████████| 1000/1000 [00:17&lt;00:00, 57.19it/s, init loss: 711863.6250, avg. loss [951-1000]: 705859.1250]
100%|██████████| 1000/1000 [00:17&lt;00:00, 57.17it/s, init loss: 705953.6875, avg. loss [951-1000]: 702366.8125]
100%|██████████| 1000/1000 [00:17&lt;00:00, 57.16it/s, init loss: 702441.9375, avg. loss [951-1000]: 700419.1250]
100%|██████████| 1000/1000 [00:17&lt;00:00, 57.12it/s, init loss: 700093.9375, avg. loss [951-1000]: 698991.6875]
100%|██████████| 1000/1000 [00:17&lt;00:00, 57.04it/s, init loss: 699521.0000, avg. loss [951-1000]: 696912.8125]
100%|██████████| 1000/1000 [00:17&lt;00:00, 57.04it/s, init loss: 696551.1875, avg. loss [951-1000]: 693607.8125]
100%|██████████| 1000/1000 [00:17&lt;00:00, 57.00it/s, init loss: 693494.9375, avg. loss [951-1000]: 693099.8125]</code></pre>
<pre class="python"><code>samples = guide.sample_posterior(jax.random.PRNGKey(0), svi_result.params, sample_shape=(5,))</code></pre>
<pre class="python"><code>fig, axes = plt.subplots(1, 3, figsize=(10, 5))
fig.colorbar(axes[0].imshow(samples[&#39;val&#39;][0], cmap=&#39;gray&#39;), ax=axes[0], fraction=0.03, pad=0.04)
axes[0].set_title(&#39;Prediction&#39;)
fig.colorbar(axes[1].imshow(jnp.abs(samples[&#39;diff&#39;][0]), cmap=&#39;gray&#39;), ax=axes[1], fraction=0.03, pad=0.04)
axes[1].set_title(&#39;Difference&#39;)
fig.colorbar(axes[-1].imshow(hsv_img[:,:,0], cmap=&#39;gray&#39;), ax=axes[-1], fraction=0.03, pad=0.04)
axes[-1].set_title(&#39;Ground truth&#39;)
fig.tight_layout()</code></pre>
<figure>
<img src="2024-12-28-droplet-generative-process_files/2024-12-28-droplet-generative-process_15_0.png" alt="" /><figcaption>png</figcaption>
</figure>
<p>Not a bad start</p></div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.2/highlight.min.js"></script>
    <script>
      hljs.highlightAll();
    </script>
  </body>
</html>
