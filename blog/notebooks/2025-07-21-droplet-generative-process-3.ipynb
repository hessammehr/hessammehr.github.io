{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trialing probabilistic modelling for chemical microscopy (part 3)\n",
    "\n",
    "Can we used an amortized model to speed up inference in our droplet microscopy model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m4_HSSzum5p-"
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.nn as jnn\n",
    "import flax.linen as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpyro.distributions as dist\n",
    "import seaborn as sns\n",
    "from numpyro import deterministic, plate, sample\n",
    "from numpyro.handlers import seed, trace, substitute\n",
    "from numpyro.infer import SVI, Trace_ELBO, MCMC, NUTS\n",
    "from numpyro.infer.autoguide import AutoNormal\n",
    "from numpyro.optim import Adam\n",
    "from PIL import Image\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "\n",
    "sns.set_theme(context='paper', style='ticks', font='Arial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "reBZ6B2_m91F",
    "outputId": "dbc73dd7-fb8d-49ca-fae2-8a3e04748d95"
   },
   "outputs": [],
   "source": [
    "img = Image.open('data/example.jpg')\n",
    "img = img.resize((img.width // 4, img.height // 4))\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, we'll focus on modeling the H (hue) channel of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 831
    },
    "id": "vL-RYeQpnCCT",
    "outputId": "28c4a842-0dd8-4d32-e03e-a0edd4fb19f2"
   },
   "outputs": [],
   "source": [
    "img_hsv = np.array(img.convert('HSV')) / 255.0\n",
    "\n",
    "plt.imshow(img_hsv[..., 0], cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropletOpticsModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural network model for amortized inference of droplet optics.\n",
    "    \n",
    "    Takes pixel background values, distance from droplet, droplet radius,\n",
    "    and droplet composition to predict new pixel values.\n",
    "    \"\"\"\n",
    "    hidden_dims: tuple = (32, 16, 8)\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, background, dx, dy, radius, composition):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            background: (batch, n_channels) - existing/background pixel values\n",
    "            dx: (batch, 1) - normalized distance from droplet center in x-direction\n",
    "            dy: (batch, 1) - normalized distance from droplet center in y-direction\n",
    "            radius: (batch, 1) - droplet radius\n",
    "            composition: (batch, n_composition_features) - droplet composition vector\n",
    "        \n",
    "        Returns:\n",
    "            new_pixel_value: (batch, n_channels) - predicted new pixel values\n",
    "        \"\"\"\n",
    "        # Concatenate all input features\n",
    "        x = jnp.concatenate([background, dx, dy, radius, composition], axis=-1)\n",
    "\n",
    "        for i, dim in enumerate(self.hidden_dims):\n",
    "            x = nn.Dense(dim, name=f'hidden_{i}')(x)\n",
    "            x = nn.LayerNorm(name=f'ln_{i}')(x)\n",
    "            x = jnn.relu(x)\n",
    "        \n",
    "        # Output layer - predict change in pixel values\n",
    "        delta = nn.Dense(background.shape[-1], name='output')(x)\n",
    "        \n",
    "        # Add residual connection and apply sigmoid to keep values in [0, 1]\n",
    "        new_pixel_value = jnn.sigmoid(background + delta)\n",
    "        \n",
    "        return new_pixel_value\n",
    "\n",
    "# Initialize model\n",
    "model = DropletOpticsModel()\n",
    "\n",
    "# Test with dummy data\n",
    "key = jax.random.PRNGKey(42)\n",
    "batch_size, n_channels, n_composition = 32, 3, 10\n",
    "\n",
    "dummy_background = jax.random.uniform(key, (batch_size, n_channels))\n",
    "dummy_dx = jax.random.uniform(key, (batch_size, 1), minval=-1.0, maxval=1.0)\n",
    "dummy_dy = jax.random.uniform(key, (batch_size, 1), minval=-1.0, maxval=1.0)\n",
    "dummy_radius = jax.random.uniform(key, (batch_size, 1)) * 0.1  # Small radii\n",
    "dummy_composition = jax.random.uniform(key, (batch_size, n_composition))\n",
    "\n",
    "# Initialize parameters\n",
    "print(f\"{dummy_background.shape=}, {dummy_dx.shape=}, {dummy_dy.shape=}, {dummy_radius.shape=}, {dummy_composition.shape=}\")\n",
    "params = model.init(key, dummy_background, dummy_dx, dummy_dy, dummy_radius, dummy_composition)\n",
    "\n",
    "# Test forward pass\n",
    "output = model.apply(params, dummy_background, dummy_dx, dummy_dy, dummy_radius, dummy_composition)\n",
    "print(f\"Input background shape: {dummy_background.shape}\")\n",
    "print(f\"Output pixel values shape: {output.shape}\")\n",
    "print(f\"Output range: [{output.min():.3f}, {output.max():.3f}]\")\n",
    "\n",
    "# Print model summary\n",
    "print(f\"\\nModel summary:\")\n",
    "print(model.tabulate(key, dummy_background, dummy_dx, dummy_dy, dummy_radius, dummy_composition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_background.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_to_dists(tree, path=''):\n",
    "    if isinstance(tree, dict):\n",
    "        return {k: tree_to_dists(v, path + '/' + k) for k, v in tree.items()}\n",
    "    else:\n",
    "        # print(f\"Sampling {path} with shape {tree.shape}\")\n",
    "        return sample(path, dist.Normal().expand(tree.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b8TdKHaYnkQA"
   },
   "outputs": [],
   "source": [
    "def model_with_nn(img, n_droplets, types=10):\n",
    "    h, w, n_channels = img.shape\n",
    "    \n",
    "    # Create coordinate grids\n",
    "    y_coords, x_coords = jnp.mgrid[:h, :w]\n",
    "    \n",
    "    # Sample background per channel\n",
    "    with plate(\"channels\", n_channels):\n",
    "        bg = sample(\"bg\", dist.Uniform(0, 1))\n",
    "\n",
    "    # Sample droplet parameters\n",
    "    with plate(\"droplets\", n_droplets):\n",
    "        x = sample(\"x\", dist.Uniform(0, w))\n",
    "        y = sample(\"y\", dist.Uniform(0, h))\n",
    "        r = sample(\"r\", dist.LogNormal(0, 0.5))\n",
    "        with plate(\"types\", types):\n",
    "            composition = sample(\"composition\", dist.Uniform(0, 1))\n",
    "\n",
    "    model = DropletOpticsModel()\n",
    "\n",
    "    # Initialize background image\n",
    "    prediction = jnp.broadcast_to(bg, (h, w, n_channels))\n",
    "    nn_params = model.init(key, \n",
    "                           jnp.zeros((h * w, n_channels)), \n",
    "                           jnp.zeros((h * w, 1)),\n",
    "                           jnp.zeros((h * w, 1)),\n",
    "                           jnp.zeros((h * w, 1)),\n",
    "                           jnp.zeros((h * w, types)))    \n",
    "    nn_params = tree_to_dists(nn_params)\n",
    "    # For each droplet, compute its effect using the neural network\n",
    "    for i in range(n_droplets):\n",
    "        # Calculate relative distances from droplet center\n",
    "        dx = (x_coords - x[i]) / r[i]  # Normalized by radius\n",
    "        dy = (y_coords - y[i]) / r[i]  # Normalized by radius\n",
    "        \n",
    "        # Flatten spatial dimensions for neural network processing\n",
    "        dx_flat = dx.flatten()[:, None]\n",
    "        dy_flat = dy.flatten()[:, None]\n",
    "        r_flat = jnp.full((h * w, 1), r[i])\n",
    "        \n",
    "        # Repeat background and composition for all pixels\n",
    "        bg_flat = jnp.broadcast_to(prediction.reshape(-1, n_channels), (h * w, n_channels))\n",
    "        comp_flat = jnp.broadcast_to(composition[:, i], (h * w, types))\n",
    "        \n",
    "        # print(f\"{bg_flat.shape=}, {dx_flat.shape=}, {dy_flat.shape=}, {r_flat.shape=}, {comp_flat.shape=}\")\n",
    "        # Apply neural network to get new pixel values\n",
    "        new_pixels = model.apply(nn_params, bg_flat, dx_flat, dy_flat, r_flat, comp_flat)\n",
    "        \n",
    "        # Reshape back to image dimensions\n",
    "        new_pixels = new_pixels.reshape(h, w, n_channels)\n",
    "        \n",
    "        # Update prediction (could be additive or replacement - using replacement here)\n",
    "        prediction = new_pixels\n",
    "    \n",
    "    prediction = jnp.clip(prediction, 0, 1)\n",
    "    prediction = deterministic('prediction', prediction)\n",
    "    diff = deterministic('diff', img - prediction)\n",
    "    sample('obs', dist.Normal(scale=0.05), obs=diff)\n",
    "    return nn_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the integrated model\n",
    "test_img = jnp.ones((50, 50, 3)) * 0.5  # Small test image\n",
    "\n",
    "# Use the neural network parameters from the model we initialized earlier\n",
    "tr = trace(seed(model_with_nn, 0)).get_trace(test_img, 3, types=5)\n",
    "nn_params = seed(model_with_nn, 0)(test_img, 3, types=5)\n",
    "{k: v['value'].shape for k, v in tr.items() if 'value' in v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc = MCMC( NUTS(model_with_nn), num_warmup=1000, num_samples=1000)\n",
    "mcmc.run(jax.random.PRNGKey(0), test_img, 3, types=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = trace(seed(model, 0)).get_trace(np.array(img), 15)\n",
    "{k: v['value'].shape for k, v in tr.items() if 'value' in v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 909
    },
    "id": "ao9ae2b_weDF",
    "outputId": "0a68a1d6-7b7d-4e9f-fe99-ee7f1771938e"
   },
   "outputs": [],
   "source": [
    "guide = AutoNormal(model)\n",
    "svi = SVI(model, guide, Adam(0.01), Trace_ELBO())\n",
    "\n",
    "svi_result = svi.run(jax.random.PRNGKey(0), 100000, img.width, img.height, 2000, img_hsv[..., 0])\n",
    "samples_svi = guide.sample_posterior(jax.random.PRNGKey(0), svi_result.params, sample_shape=(100,))\n",
    "fig, ax = plt.subplots(figsize=(5, 2))\n",
    "ax.plot(svi_result.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 825
    },
    "id": "mZ9Dn3ajttnV",
    "outputId": "52317b26-4517-4097-c533-7c743568d476"
   },
   "outputs": [],
   "source": [
    "plt.imshow(samples_svi['img'].mean(axis=0), cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks quite good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 831
    },
    "id": "egIUqPZSnppT",
    "outputId": "63a3fcf6-5c0e-4297-8834-98ca651227c0"
   },
   "outputs": [],
   "source": [
    "plt.imshow(img_hsv[:, :, 0]/255.0, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.scatter(samples_svi['x'][:100] * img_hsv.shape[1], samples_svi['y'][:100] * img_hsv.shape[0], s=4, alpha=0.01, c='red', marker='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most droplets are now detected â€” very nice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the inferred droplet masks:"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
