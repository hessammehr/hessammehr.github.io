{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05fef693",
   "metadata": {},
   "source": [
    "# Live variational inference\n",
    "\n",
    "This is mostly to show two possibilities:\n",
    "\n",
    "* The ability to update the data going into a model in the course of running variational inference. Imagine you are accumulating data as you go, or (this is more technical/hacky) you find that your multimodal distributions get locked into a specific mode that the optimiser cannot escape and are looking for a way to \"ease into\" the right mode by e.g. tightening your Dirichlet concentration factor gradually as you go.\n",
    "* Inspect model predictions and loss in real time.\n",
    "\n",
    "The key is using the `SVI.update` call, which I have avoided so far for the convenience of `SVI.run`. A batch of steps can be take in a jitted loop for performance and the loss monitored for convergence every time a parameter/input data is changed.\n",
    "\n",
    "With `matplotlib` you need to use an interactive backend like `qt` or `osx` and add a `plt.pause(...)` call in the loop to make sure there is a chance to re-render the figure. Super useful and something I didn't know about (thanks ChatGPT).\n",
    "\n",
    "A minimal example below, where the concentration parameter for a Dirichlet prior to a categorical observation is varied smoothly from 1.0 (i.e. flat) to 0.1 (pretty pointy at the extremes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccab2091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Invalid GUI request 'macosx', valid ones are:dict_keys(['inline', 'nbagg', 'webagg', 'notebook', 'ipympl', 'widget', None, 'qt', 'qt5', 'qt6', 'wx', 'tk', 'gtk', 'gtk3', 'osx', 'asyncio'])\n"
     ]
    }
   ],
   "source": [
    "%matplotlib osx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f53b4346",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:06<00:00, 14.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior theta mean: [1.26911415e-08 7.69821611e-08 6.65301085e-01 7.23654193e-06\n",
      " 1.26773830e-06 2.86240101e-01 2.82157103e-10 9.47567692e-04\n",
      " 2.23408958e-10 4.75026183e-02 6.67153069e-11 5.59603919e-09]\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from numpyro.infer import SVI, Trace_ELBO, autoguide\n",
    "from numpyro.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "sns.set_theme(\n",
    "    \"talk\", \"ticks\", font=\"Arial\", font_scale=1.0, rc={\"svg.fonttype\": \"none\"}\n",
    ")\n",
    "\n",
    "num_steps = 100\n",
    "\n",
    "\n",
    "def model(alpha_scale):\n",
    "    alpha = jnp.ones(12) * alpha_scale\n",
    "    theta = numpyro.sample(\"theta\", dist.Dirichlet(alpha))\n",
    "    numpyro.sample(\"obs1\", dist.Categorical(theta), obs=jnp.array([2,2,2,2,2,5,5,5]))\n",
    "\n",
    "guide = autoguide.AutoNormal(model)\n",
    "\n",
    "optimizer = Adam(1e-3)\n",
    "svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "rng_key = jax.random.PRNGKey(0)\n",
    "state = svi.init(\n",
    "    rng_key,\n",
    "    alpha_scale=1.0,\n",
    ")\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def run_stage(state, init_loss, alpha_scale):\n",
    "    def body_fn(i, val):\n",
    "        return svi.update(val[0], alpha_scale)\n",
    "\n",
    "    return jax.lax.fori_loop(0, 100, body_fn, (state, init_loss))\n",
    "\n",
    "\n",
    "f, (a1, a2) = plt.subplots(nrows=2, sharex=True)\n",
    "a1.set(ylabel=\"ELBO loss\")\n",
    "a2.set(xlabel=\"SVI batch\", ylabel=r\"$\\theta$ (posterior)\")\n",
    "f.tight_layout()\n",
    "for i in tqdm(range(num_steps)):\n",
    "    alpha_scale = 0.02 ** (i / num_steps)\n",
    "    a1.set_title(f\"$\\\\alpha$: {alpha_scale:.2f}\")\n",
    "    while True:\n",
    "        # Run SVI steps until convergence\n",
    "        init_loss = svi.evaluate(state, alpha_scale)\n",
    "        state, loss = run_stage(state, init_loss, alpha_scale)\n",
    "        if jnp.abs(loss - init_loss) / np.abs(init_loss) < 0.02:\n",
    "            break\n",
    "    params = svi.get_params(state)\n",
    "    a1.scatter([i], loss, c=\"k\", s=5)\n",
    "    posterior = guide.sample_posterior(rng_key, params)\n",
    "    theta = posterior[\"theta\"]\n",
    "    a2.scatter(i * np.ones_like(theta), theta, c=np.arange(12), s=5)\n",
    "    # This is really important to get live updates.\n",
    "    plt.pause(0.01)\n",
    "\n",
    "f.savefig(\"2025-10-15-live-svi_result.svg\")\n",
    "print(\"Posterior theta mean:\", posterior[\"theta\"])\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7139beff",
   "metadata": {},
   "source": [
    "Not sure if the result will show up as expected when this notebook is converted to HTML but it looks very nice and it's good to be able to see it converge.\n",
    "\n",
    "![The result](2025-10-15-live-svi_plot.svg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
